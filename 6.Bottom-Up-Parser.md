# Parser bottom up

Di base fa una derivazione al contrario: parte dalla stringa di input (che è sempre una stringa di token) e cerca di
risalire all'assioma.

Chiamiamo $\alpha_i$ le varie forme di frase. $\alpha_0$ è una stringa di token e dobbiamo risalire fino ad $\alpha_k$.

Poniamo che $\alpha_i = \gamma \beta \delta$, se il parser "si accorge" che c'è una parte destra di una produzione,
allora la forma di frase successiva (come ritorno all'assioma) è l'applicazione della produzione.

Passo da una forma alla successiva sostituendo una parte destra con la testa della produzione. L'obiettivo è arrivare a
un $\alpha_k$ che è l'assioma.

Sostituire una parte destra con la sua testa è detto _riduzione_. Il parser bottom-up procede per riduzioni.

## shift-reduce

Un tipo di parser bottom-up molto diffuso è quello di tipo _shift-reduce_ che sono le due operazioni paradigmatiche che
fa il parser. Anche qui si fa prima il lavoro di predisporre delle tabelle di parsing, mentre il fenomeno del parsing
in sè è molto semplice. Serve uno stack di appoggio.

- `shift`: spostamento del carattere dall'input allo stack;

- `reduce`: individuazione sulla cima dello stack di una parte destra di produzione e applicazione di una riduzione.
L'individuazione sulla cima è possibile se facciamo una derivazione canonica destra.

Un parser bottom-up non ha problemi con ricorsioni sinistre.

L'attuale forma di frase si ottiene concatenando idealmente lo stack e l'input. Deduciamo che la prima azione eseguita
è uno shift. Nell'esempio delle slide 6 e 7 stiamo considerando un parser (errato) "greedy", ma questo approcio non può
funzionare.

Guardando le produzioni del parser "corretto" al contrario, ci accorgiamo che sono canoniche destre. Questo è una
conseguenza che la parte destra della produzione da utilizzare è sempre in cima allo stack.
Non sarebbe vero se il parser facesse delle derivazioni canoniche sinistre.

Abbiamo ancora il problema di capire quando fare shift e quando fare reduce.

## Handle

È la parte destra giusta da utilizzare. Ad ogni momento ne esiste al più di una, ed è sempre in cima allo stack. Quando
non ce n'è alcuna bisogna fare uno shift.

## Parser LR

L'esempio più semplice, e quello che andremo a realizzare. Un parser LR ha accesso a un input sequenziale: chiamiamo il
lexer che _consuma_ un token dall'input.

Il controllo ha uno stack rispetto alla descrizione generica del parser shift-reduce non memorizza simboli, ma stati di
un automa che dobbiamo costruire...

Inoltre ha accesso a una tabella di parsing divisa in due parti: `action` e `goto`. Entrambe sono indicizzate per righe
dagli stati (gli stessi oggetti che vengono messi sulla pila).

A un generico passo il parser guarda simbolo in input e stato. In `action` ci può essere: `shift` e in che stato andare.
Nello stack viene messo quello stato, non un input. Se invece c'è `reduce` il parser può fare pop dallo stack di tanti
simboli quanti sono i simboli nella parte destra della produzione.

Fatte queste pop sulla cima dello stack emerge uno stato: a quel punto il parser accede alla tabella in `goto`, c'è
scritto un altro stato da mettere nello stack e riparto.

Vediamo un esempio sulla grammatica:

$$
S \to (S)S \\
S \to \epsilon
$$

che genera il linguaggio delle parentesi bilanciati, che è context-free e non regolare.

Senza costruirla (per ora) consideriamo la tabella di parsing. Numeriamo le produzioni in base all'ordine in cui le
incontriamo. Come simboli terminali per la parte action abbiamo le parentesi e il fine stringa.

## Parsing SLR

Aumentiamo la grammatica G con una produzione aggiuntiva: $S' \to S$, dove S è l'assioma originale della gramttica.
Serve per normalizzare "in qualche modo" l'automa, lo stato che porta all'accettazione sarà sempre lo stato 1. Detto
questo guardiamo tutte le produzioni, che possono dare origine a un certo numero di stati.

Associati ad ogni produzione, introduciamo degli oggetti astratti detti `item`. Un item è una produzioni con inserito
un marcatore.

Il puntino • sta ad indicare il punto in cui il processo di parsing è arrivo. Se metto • davanti a un rhs di una
produzione vuol dire che il parsing è arrivato a dover riconoscere la parte destra di una produzione.

$$
(1) \ S \to • (S)S
$$

invece nel caso

$$
(2) \ S \to (•S)S
$$

vuol dire che abbiamo riconosciuto una parentesi aperta e adesso dobbiamo di nuovo riconoscere una sequenza di
parentesi. Per capire questo pezzo adesso dobbiamo applicare un procedimento ricorsivo.

Se siamo nel punto di (2) allora siamo di nuovo a (1), ma siccome $S \to \epsilon$ che si riscrive come $S \to •$ allora
potrei essere anche lì. Dobbiamo quindi calcolare per ogni item la sua _closure_.

## Item closure

Consideriamo la grammatica aumentata:

$$
S' \to S \\
S \to (S)S | \epsilon
$$

...

Consideriamo il linguaggio di una sequenza di a seguita da una sequenza di altrettante b. Sempre aumentata.

$$
S' \to S \\
S \to aSb | ab
$$

Stato 0:

$$
S' \to •S \\
S \to •aSb \\
S \to •ab \\
$$

le due righe sotto sono date dal fatto che il • è prima di un non terminale, quindi devo seguire e metterlo all'inizio
della parte destra.

Stato 1:

$$
S' \to S•
$$

non ho altro da fare

Stato 2:

mando avanti $S \to •aSb$:

$$
S \to a•Sb \\
S \to a • b \\
S \to •aSb
S \to •ab
$$

se riconosco una S vado nello stato 3

Stato 3:

$$
S \to aS • b
$$

se riconosco una b vado nello stato 5

Stato 4:

$$
S \to ab•
$$

Stato 5:

$$
S \to aSb•
$$

> Ogni stato descrive con l'insieme dei suoi item, la situazione in cui si trova il parser.

Il numero di stati ha un upper bound... $%TODO: qual è?$.

La stranezza degli automi generati è che ha delle transizioni etichettate con qualcosa che in input non si vedrà mai.
Come vanno interpretate?

Quando riconosco una sequenza è come se potessi comprimerla: è esattamente quello che succede in reduce.

## Follow

"Ricicliamo" un concetto che avevamo visto negli altri parser.

## Tabelle

Il parser utilizza due tabelle per operare: tabella ACTION e tabella GOTO.

Se abbiamo una transizione da j a k etichettata con un terminale X, poniamo ACTION[j, X] = shift k.

Se abbiamo una transizione da j a k etichettata con un non terminale X, poniamo GOTO[j, X] = k.

Se negli item di j, ce n'è uno con il marker alla fine, ovvero un qualche handle $A \to \alpha •$,
allora poniamo ACTION[j, X] = reduce $A \to \alpha$ per ogni X nel FOLLOW(A).

Se l'insieme j contiene la riduzione dell'assioma, ovvero l'item $S' \to S •$ allora poniamo
ACTION[j, $] = accept.

Da queste regole le tabelle sono così caratterizzate: ACTION è sempre indicizzata per simboli terminale,
mentre GOTO è indicizzata solo con non terminali sulle colonne.

Entrambe le tabelle fanno parte della tabella di transizione del parser. L'operazione di shift legge
un carattere dall'input mentre la reduce sostituisce gli ultimi k simboli con A.

Una riduzione non inserisce alcun stato sullo stack, ma si inserisce lo stato di GOTO per lo stato q'
che si trova in cima allo stack dopo la riduzione.