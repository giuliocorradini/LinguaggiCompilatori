# Introduzione

Obiettivo della prima parte del corso è creare un front-end per l'infrastruttura di LLVM per un linguaggio giocattolo.
Creeremo una rappresentazione intermedia del codice platform-independent che andremo a compilare nella seconda parte
del corso.

## Perché studiare i compilatori?

Progettare un compilatore è veramente complesso e a livello di software engineering è un ottimo esercizio.

I compilatori caratterizzano l'informatica come disciplina scientifica, e questa è una delle prime. La teoria dei
compilatori è una delle prime e delle più utili messe a punto.

## Cosa bisogna conoscere?

Algoritmi e strutture dati: il compilatore produce un AST (abstract syntax tree), una rappresentazione alternativa del
codice che viene utilizzata nel processo di compilazione, navigando quest'albero.

Programmazione in C++ e padronanza del paradigma ad oggetti. Proprio il C++ perché è il linguaggio utilizzato in LLVM.

Dimestichezza con l'assembly per questa prima parte. Serve per la rappresentazione intermedia di LLVM che comincia già
a trattare registri.

## Cos'è il compilatore?

Il compilatore da solo non fa niente, viene usato in una _toolchain_: una catena di strumenti che vanno usati in
sequenza e comprende in ordine:

- precompilatore/preprocessore

- compilatore

- assemblatore

- linker (statico o dinamico)

il linking dinamico avviene a runtime.

Tutti questi programmi non vengono invocati direttamente, ci sono dei driver (tipo g++) che chiamano le varie
componenti. Si possono anche chiamare manualmente in sequenza, se necessario.

Toolchain completa (per il C++, con gcc), su Debian:

`sorgente (.cpp) -> | preprocessor [cpp] | -> pre-elaborato (.ii)`

Il sorgente include gli header ed espande le macro. Il pre-elaborato è ancora human-readable, ma molto lungo.

`pre-elaborato -> | compilatore [cc1plus] | -> assembly (.S)`

`cc1plus` non è normalmente incluso nel PATH ma si può trovare e invocare direttamente.

`assembly -> | assembler [ad] | -> codice oggetto (.o)`

Infine il linker prende i vari oggetti `.o` e li assembla per produrre un eseguibile che può essere lanciato.

### Test

```c++
#include <iostream>
using namespace std;

int main() {
    cout << "Hello, world\n";

    return 0;
}
```

1. Preprocessing

```sh
cpp -o hw.ii hw.cpp
```

2. Compilazione vera e propria

```sh
cc1plus -o hw.S hw.ii
```

3. Assemblatore

```sh
as -o hw.o hw.S
```

4. Linking

È più difficile da fare... proviamo a usare g++.

```sh
g++ -v hw.cpp
```

e vediamo che `ld` ha bisogno di un numero infinito di parametri.

La generazione del codice avviene in 4-1-2 fasi: le prime quattro si studiano in questo corso e fanno parte del front
end del compilatori. La seconda macro-fase è l'ottimizzazione technology independent della rappresentazione intermedia
mentre le ultime due fasi sono l'effettiva compilazine in codice macchina.

(La struttura è descritta nel libro a pagina 5)

A livello tecnico parlare di linguaggi compilati e interpretati è un abuso di linguaggio perché i linguaggi sono sempre
entrambe le cose.

L'interprete dà l'impressione che il sorgente giri direttamente sulla macchina. Una soluzione così brutale dove esiste
solo l'interpretazione pura è il LISP, altri usano soluzioni ibride.

L'interprete puro è molto inefficiente perché si perde tempo, a ogni esecuzioni, per l'analisi del sorgente.

Le soluzioni intermedie offrono due possibilità:

- i linguaggi come Python o Java vengono prima compilati in bytecode, poi c'è un interprete che esegue questo codice.
La differenza principale è che in Python è tutto trasparente, mentre Java richiede un'esplicita generazione del bytecode
che è il codice macchina della macchina virtuale che esegue il codice intermedio.

Si possono fare ottimizzazioni, come compilare just-in-time.

- l'altra famiglia, quella del PERL, offre un linguaggio la cui implementazione tipica è mediante interpretazione.
Il PERL si ferma a un AST, l'interprete esegue l'AST.

Il front-end è la parte di compilatore che "conosce il linguaggio", mentre il back-end "conosce la macchina" e produce
il codice sorgente.

Conto combinatoriale: supponiamo di produrre compilatori. Abbiamo 5 linguaggi e 5 architetture, se volessi supportare
ogni linguaggio su ogni architettura dovrei preparare 25 compilatori diversi.
Il modo migliore è definire un linguaggio intermedio indipendente sia dai linguaggi che dalle architetture. Grazie
allo snodo del codice intermedio devo sviluppare solo 5 backend e 5 frontend.

Nel corso vedremo l'IR (intermediate representation) dell'LLVM. Possiamo compilare qualsiasi linguaggio e possiamo
compilarlo verso qualsiasi architettura.

## Il flusso in dettaglio

In una lingua il lessico è l'insieme delle parole. Nel caso di un linguaggio di programmazione, l'analizzatore lessicale
è un software che raggruppa i caratteri, riconosce sequenze di caratteri come oggetti lessicalmente rilevanti (numeri,
identificatori, operatori, keyword...);

di modo che l'analizzatore sintattico (il modo in cui le parole vengono unite per formare frasi corrette) possa
analizzare i token (che sono strutture dati astratte) che verifica che il programma sia sintatticamente corretto.
In uscita produce un albero: l'abstract syntax tree. Rappresenta la struttura del programma in modo bidimensionale.

L'analizzatore semantico fa ulteriori controlli, ad esempio se scrivo `i = x + y` per l'analizzatore lessicale e
sintattico va tutto bene, ma l'analizzatore semantico controlla ad esempio che i tipi delle variabili siano compatibili.
Oppure si controlla che il numero dei parametri di una funzione sia corretto, questo potrebbe essere anche sintattico
ma di solito si fa a livello semantico.

In uscita c'è ancora l'albero ma con più informazioni.

L'ultima fase è la rappresentazione intermedia a partire dall'albero semantico.

Applichiamo il modello a una singola istruzione `position = initial + rate * 60;`

### Analizzatore lessicale (lexer)

Trasforma la sequenza di caratteri in una sequenza di Token: `<id, 1> <=> <id, 2> <+> <id, 3> <*> <60>`.
Ha riconosciuto che `position` è un identificatore, e ha costruito un token id. Dal punto di vista sintattico non cambia
niente e questo semplifica moltissimo la fase di analisi sintattica.

[Tecnicamente composto da scanner e analizzatore lessicale]

### Analizzatore sintattico (parser)

Non si occupa dei nomi specifici, tanto non cambia nulla. L'id 1 è un puntatore, una entry, della symbol table ma viene
usato in un secondo momento.

In realtà non è il lexer a passare i token al parser, ma è il parser che chiede sequenzialmente i token al lexer che è
una sua subroutine.

Nel token c'è anche la posizione nel file sorgente in termini di coppia riga-colonna, per dare informazioni diagnostiche
in caso di errore nel codice sorgente. Ci serve perché il lexer è l'unica parte che vede il sorgente.

Facciamo finta di voler fare il parsing di un `if`, questo avrà 3 figli: la condizione, il ramo then e il ramo else.

> Qualsiasi costrutto programmativo può essere scritto come un albero.

Un'interprete inefficiente si può già fare a partire da un albero, con una struttura dati d'appoggio.
Si possono fare anche delle ottimizzazioni, corto-circuiti nell'albero.

### Analisi semantica

L'analizzatore semantico si è accorto che rate è float, quindi 60 va trasformato in float. L'albero va ad aggiungere
un'istruzione di `inttofloat`.

### Generatore di IR

Potrebbe produrre codice inefficiente abusando ad esempio dei registri temporanei. Meglio sprecare in una prima fase per
agevolare la correttezza.

### Symbol table

Opportunamente implementata permette di fare scoping, che definisce la visibilità e la vita di un identificatore.

In un compilatore estremamente efficiente non si costruisce un AST esplicito, a livello didattico invece è utile.
