# Kaleidoscope

Kaleidoscope è un linguaggio a paradigma funzionale. Illustriamo questo modo di pensare il software.
Per scopi didattici aggiungeremo dei costrutti di tipo operativo.

Un linguaggio funzionale è uno stile di programmazione in cui non esiste il concetto di memoria. C'è il concetto di
ambiente, quindi gli identificatori vanno pensati direttamente legati agli oggetti.

In un linguaggio tipo il C, una definizione di questo tipo:

```c
int a = 1;
```

è modellata con due funzioni. Una che mappa gli identificatori a una zona di memoria, che viene chiamata _ambiente_,
poi c'è una seconda funzione che mappa locazioni di memoria con valori _store_.

> Un linguaggio imperativo ha sia ambiente che memoria.

Le definizioni modificano l'ambiente, mentre gli assegnamenti modificano lo store. Naturalmente questa cosa vale anche
per oggetti più complessi.

Questo ci dà il vantaggio di poter riutilizzare la memoria, che è anche la più grande fonte di bug.

Nel paradigma funzionale c'è una corrispondenza diretta tra gli identificatori e i valori. Se in Python non esistessero
oggetti non Immutable, come le liste, allora avremmo un linguaggio funzionale puro.

```
a = 1
a = 2
```

in un linguaggio funzionale, l'assegnazione non modifica la zona di memoria identificata da a. Anche in Python succede
questo.

Dal punto di vista modellistico dobbiamo pensare che **non ci sia memoria**, quindi una cosa del genere non la possiamo
fare:

```python
a = "pippo"
a[1] = 'o'
```

Non cambia la memoria, ma cambia l'environment. Non c'è il doppio passaggio come in C.

Ma questa cosa non è pesante dal punto di vista delle risorse? Vero, ma un linguaggio funzionale è estremamente
semplice da debuggare. Non ho l'assegnamento ma espressioni e chiamate a funzione.

Il risultato non può essere salvato in una variabile ma viene passato a un'altra funzione o utilizzato in un'espressione.

> I linguaggi funzionali sono Turing-completi. Posso fare tutto, ma con un altro stile.

Dal punto di vista dell'efficienza è conveniente permettere che le funzioni abbiano dei side-effect. Side-effect e
store sono la causa del 95% degli errori di programmazione.

Facciamo un confronto:

| Stile imperativo | Stile funzionale |
|------------------|------------------|
| `int V=0; for(int i=0; i<n; i++) V = V+X[i];` | `` |

Il paradigma funzionale è ancora utilizzato.

Esempio di serie di Fibonacci in Kaleidoscope:

```kal
def fib(n)
    if x<=1
        then 1
    else fib(n-1) + fib(n-2)
```

tutto è espressione, quindi anche l'if può essere passato come parametro a una funzione.

Per "compilare" il codice in Kaleidoscope, possiamo usare `kalcomp` che ha anche una versione verbose `-v`.
Produce una rappresentazione intermedia (IR) per LLVM. Può essere ancora oggetto di svariate ottimizzazioni.

## Definizione funzioni

Si contrassegnano con `def`. I parametri formali sono separati da spazi e poi abbiamo un'espressione.

Una funzione esterna può essere definita con `extern`.

## Grammatica

Dalla slide 37. Un programma Kaleidoscope può essere un `top` seguito da un `programma` (ricorsivo). $\epsilon$ chiude
la ricorsione e ottengo che un programma è una sequenza di top seguiti da `;`.

Un `top` può essere `def` oppure `external` oppure `expr` oppure un $\epsilon$, quindi posso avere `;;` di seguito.

Una funzione `extern` è identificata dal terminale _extern_ con un `proto` prototipo.

Un `def` è il terminale _def_ seguito da un prototipo e un'espressione.

Manca da dire cos'è un'espressione, la cosa sarà un po' più complicata. L'unica convenzione è che `program` sia la
produzione iniziale.

Per prendere pratica con Kaleidoscope proviamo a scrivere dei programmi che rispettino questa sintassi.

## Parsing top-down

Un parser a discesa ricorsiva è pesante perché fa backtracking. Visto che non possiamo realizzare un parser non
deterministico, realizziamo un parser predittivo.

Andiamo a vedere il primo simbolo non terminale in input (il prossimo simbolo quindi).

Consideriamo la grammtica

$$
A \to aA | bB \\
B \to \epsilon | bB
$$

Parliamo di derivazioni canoniche sinistre.

Nel caso di una grammatica LL (left-left) un parser predittivo può essere agevolmente realizzato. In generale possiamo
considerare grammatiche con k caratteri di lookahead LL(k). Noi lavoriamo su LL(1).

Mettiamoci al generico passo di parsing e aver prodotto una forma di frase (passaggio intermedio della derivazione).
Siccome stiamo facendo derivazioni canoniche sinistra, possiamo descrivere la forma di frase generica i come:

$$
\alpha_i = a_1 a_2 \dots a_k A \beta
$$

Metto in evidenza il primo non terminale, perché sviluppo quello più a sinistra.

Il prossimo simbolo di input lo chiamiamo $a = a_{k+1}$ e dobbiamo svilippare. Se ci sono almeno due produzioni per $A$
quale dobbiamo applicare?

$$
A \to \gamma | \delta
$$

$\gamma$ e $\delta$ possono essere stringhe qualsiasi di terminali. La grammatica non può essere LL(1) se sia partendo
da gamma che delta e applicando un certo numero di riscrittura puoi arrivare a una stringa che comincia per $a$.

Il parser guardando un carattere non sa che produzione sarà giusta.

C'è un'altra condizione da verificare affinché la grammatica sia LL(1), se accade che una delle due parti destre è
nullificabile ovvero

$$
\gamma \Rightarrow^* \epsilon
$$

e

$$
\delta \Rightarrow^* a \delta'
$$

allora $a$ non deve essere il primo elemento derivabile da $\beta$.

Praticamente $a$ non deve mai seguire $A$ in una forma di frase.

## Risolvere

Introduciamo due funzioni: `FIRST` e `FOLLOW` (che serve anche per i parser bottom-up). Sono funzioni che restituiscono
insiemi di simboli. Se $\alpha$ (stringa di terminali e non terminali) è un insieme di simboli, allora:

> $FIRST(\alpha)$ è l'insieme di simboli terminali con cui può iniziare una frase derivabile da $\alpha$.

> $FOLLOW(\alpha)$ è l'insieme di simboli terminali che si possono trovare immediatamente a destra di una derivazione
canonica.

## First

> Se X è un terminale, allora poniamo $FIRST(x) = \{x\}$.
>
> Mentre se X è un non-terminale, allora costruiamo la funzione incrementalmente. $FIRST(X) = \{\ \}$.
>   Consideriamo le produzioni di X. Se esiste la produzione $X \to X_1 \dots X_n$ e risulta che i primi j sono
nullificabili, allora $FIRST(X) = FIRST(X) \cup \{ x \}$.

Nel caso di <external> ho come primo terminale solo `extern`.

## Follow

> Se esiste la produzione $B \to \alpha A \beta$, tutti i terminali in $FIRST(\beta)$ si inseriscono in $FOLLOW(A)$.
>
> Inoltre se $B \to \alpha A$, allora tutti i terminali che stanno in $FOLLOW(B)$ stanno anche in $FOLLOW(A)$.
> Per convenzione si mette anche il simbolo di end of file.

Calcoliamo il follow di E: cerchiamo nelle parti destre dove sta la E. Abbiamo la parentesi chiusa in $FOLLOW(E)$.

Se un follow ne include un altro e viceversa, allora sono uguali.

FOLLOW(A) = {$}

FOLLOW(B) = {$} unito FIRST(C)

FIRST(C) = {$, ...}

allora rimane la seconda regola quindi: FOLLOW(B) = {$} unito FOLLOW(A)

quindi FOLLOW(B) = {$, c}

FOLLOW(C) = FOLLOW(A)

Allora FOLLOW(A) = FOLLOW(B) = {$}.

Siamo in grado di dire formalmente quando una grammatica è LL(1).

> Se ho due produzioni relative allo stesso non terminale, i first devono essere disgiunti per avere una LL(1).

Il payoff di questo sforzo è poter costruire una tabella di parsing, per cui il parser ad ogni passo guarda il prossimo
simbolo in input e il prossimo non terminale da sviluppare. A questo punto sviluppare il parser richiede solo uno stack.
